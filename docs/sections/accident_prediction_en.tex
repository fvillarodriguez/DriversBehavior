\section{Accident Prediction}
\label{sec:accident-prediction}

\subsection{Objective}
The objective is to build and evaluate models that predict the occurrence of an accident at a gantry, using aggregated variables derived from vehicle detections (\texttt{flujos}) and, optionally, variables derived from driver \textit{clusters}.

\subsection{Data sources}
\paragraph{Flows (detections)} Each detection record contains, at minimum, a timestamp $t$, a gantry $p$, a vehicle category $c$, and a speed $v$. In the system, flows are stored in DuckDB and queried by time range.

\paragraph{Events (accidents)} Accidents come from event files. They are filtered by type \textit{Accident} and by \textit{Roadway} (by default, expressway). Then a timestamp field \texttt{accidente\_time} is constructed and the location (km, axis, carriageway) is mapped to nearby gantries using \texttt{Datos/Porticos.csv}. The assigned gantry is stored as \texttt{ultimo\_portico}.

\subsection{Temporal discretization and notation}
Time is discretized into intervals of size $\Delta$ minutes. For an observation with timestamp $t$, we define the interval start as:
\[
\tau(t)=\left\lfloor \frac{t}{\Delta}\right\rfloor \Delta.
\]
Variables are aggregated by the pair $(p,\tau)$, where $p$ is the gantry.

\subsection{Feature engineering}
\subsubsection{Macro flow variables}
For each gantry $p$, interval $\tau$, and category $c$, we define:
\[
n_{p,\tau,c} = \#\{\text{detections in }(p,\tau,c)\}, \qquad
\overline{v}_{p,\tau,c} = \frac{1}{n_{p,\tau,c}}\sum v.
\]
With $L$ lanes for normalization, hourly flow and density are computed as:
\[
q_{p,\tau,c} = \frac{60}{\Delta}\frac{n_{p,\tau,c}}{L},\qquad
k_{p,\tau,c} = \frac{q_{p,\tau,c}}{\overline{v}_{p,\tau,c}}.
\]
Optionally, dynamic variables are added via first temporal differences per gantry:
\[
\Delta \overline{v}_{p,\tau,c}=\overline{v}_{p,\tau,c}-\overline{v}_{p,\tau-\Delta,c},\qquad
\Delta k_{p,\tau,c}=k_{p,\tau,c}-k_{p,\tau-\Delta,c}.
\]
Finally, a wide matrix is constructed with columns of the form
\texttt{flow\_<cat>}, \texttt{speed\_<cat>}, \texttt{density\_<cat>}, etc.

\subsubsection{Aggregated cluster variables (optional)}
If a label file by license plate exists (\texttt{plate} $\to$ \texttt{cluster\_label}), detections are joined with their corresponding cluster and aggregated by $(p,\tau,\kappa)$, where $\kappa$ is the cluster identifier:
\[
n_{p,\tau,\kappa}=\#\{\text{detections in }(p,\tau,\kappa)\},\qquad
\mathrm{share}_{p,\tau,\kappa}=\frac{n_{p,\tau,\kappa}}{\sum_{\kappa'}n_{p,\tau,\kappa'}}.
\]
Optionally, flow, mean speed, density, and temporal differences are derived per cluster, along with a mixing measure:
\[
H_{p,\tau}=-\sum_{\kappa}\mathrm{share}_{p,\tau,\kappa}\log(\mathrm{share}_{p,\tau,\kappa}).
\]
These variables are stored as columns \texttt{cluster\_share\_*}, \texttt{cluster\_flow\_*}, \texttt{cluster\_speed\_*}, etc.

\subsection{Target definition (label)}
\label{subsec:target}
Let an accident have timestamp $t_a$ and assigned gantry $p_a$. The system defines a one-interval \textit{lead time}: the accident is labeled in the previous interval
\[
\tau_a = \tau(t_a) - \Delta,
\]
and the target is defined as:
\[
y_{p,\tau}=
\begin{cases}
1, & \text{if there exists an accident with }(p_a,\tau_a)=(p,\tau),\\
0, & \text{otherwise.}
\end{cases}
\]
Thus, $y_{p,\tau}=1$ represents ``an accident will occur in the next interval.''

\subsection{Dataset construction}
The final dataset contains, per row, a pair $(p,\tau)$ with numerical variables and \texttt{target}. Construction is:
\begin{enumerate}
  \item Compute macro flow variables by $(p,\tau)$.
  \item (Optional) Compute cluster variables by $(p,\tau)$ and join them by key \texttt{(portico, interval\_start)}.
  \item Add \texttt{target} by joining with the set of pairs $(p_a,\tau_a)$.
\end{enumerate}

\subsection{Temporal split (train/validation/test)}
To avoid temporal \textit{leakage}, a time-based split is performed using the \texttt{interval\_start} column: timestamps are ordered and the final block is assigned to test (proportion \texttt{test\_size}). In standard training, validation is also separated from the train/val block using \texttt{val\_size}.

\subsection{Imbalance handling}
Accident occurrence is rare ($y=1$). Two strategies are used:
\begin{itemize}
  \item \textbf{Class weighting}: e.g., Random Forest with \texttt{class\_weight="balanced"}.
  \item \textbf{SMOTE (optional)}: a balanced dataset is generated by applying SMOTE \emph{only on the training set}. Synthetic rows are marked with \texttt{synthetic=True} and are not used for threshold validation.
\end{itemize}

\subsection{Models}
The following models are considered:
\begin{itemize}
  \item \textbf{Random Forest}: tree ensemble with class weighting.
  \item \textbf{XGBoost}: gradient boosting with binary logistic objective.
  \item \textbf{SVM}: classifier with scaling (\texttt{StandardScaler}) and probabilistic output.
\end{itemize}
Each model produces a \textit{score} $s(x)\in\mathbb{R}$ (probability or decision function).

\subsection{Threshold calibration with FAR}
The \textit{false alarm rate} (FAR) and sensitivity are defined as:
\[
\mathrm{FAR}=\frac{FP}{FP+TN},\qquad
\mathrm{Sens}=\frac{TP}{TP+FN}.
\]
A threshold $\theta$ is selected on the validation set using the ROC curve. Given a target $\mathrm{FAR}\le \alpha$, we choose:
\[
\theta = \arg\max_{\theta:\ \mathrm{FAR}(\theta)\le \alpha}\ \mathrm{Sens}(\theta),
\]
and then evaluate on test with $\hat{y}=\mathbf{1}[s(x)\ge \theta]$.

\subsection{Evaluation metrics}
On test, we report, among others:
\[
\text{Accuracy},\ \text{Precision},\ \text{Recall},\ F1,\ \mathrm{FAR},\ \mathrm{Sens},\ \mathrm{ROC\text{-}AUC},
\]
as well as the confusion matrix.

\subsection{Feature selection and optimization}
\paragraph{Feature importance} An importance ranking is computed with Random Forest (\texttt{feature\_importances\_}) to order variables.

\paragraph{Optuna + SMOTE} Hyperparameters for the model and SMOTE are optimized. For each trial:
\begin{enumerate}
  \item Apply SMOTE on train.
  \item Train the model.
  \item Calibrate the FAR-constrained threshold on validation.
  \item Evaluate performance (e.g., F1) and select the best trial.
\end{enumerate}

\subsection{Experiments: effect of cluster variables}
To demonstrate the effect of including clusters, two scenarios are compared:
\begin{itemize}
  \item \textbf{Base}: top-$K$ variables from the baseline ranking (no clusters).
  \item \textbf{Base+Cluster}: top-$K$ variables from the combined ranking (with clusters).
\end{itemize}
This is repeated for $K=5,10,\dots$ up to the maximum available, recording metrics per configuration.

\subsection{Artifacts}
The pipeline generates artifacts in \texttt{Resultados/} (names with timestamp/suffix):
\begin{itemize}
  \item Flow features: \texttt{accident\_flow\_features\_*.csv} and/or \texttt{.duckdb}.
  \item Cluster features: \texttt{accident\_cluster\_features\_*.csv}.
  \item Balanced datasets: \texttt{accident\_balanced\_*.csv}.
  \item Optuna results: \texttt{optuna\_*.json} and \texttt{optuna\_*\_trials.csv}.
  \item Iterative experiment results: \texttt{experiments\_results\_*.csv}.
\end{itemize}